{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from jedi.api.refactoring import inline\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score\n",
        "\n",
        "#MNIST DATASET\n",
        "# Estructura de 28 X 28 pixeles = 784\n",
        "#%matplotlib inline\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "mnist = fetch_openml(name = 'mnist_784')\n",
        "\n",
        "\n",
        "#print(mnist)\n",
        "#print(len(mnist['data']))\n",
        "\n",
        "# VISUALIZACION\n",
        "X, y = mnist['data'], mnist['target']\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "y = y.astype('float')       # casting\n",
        "print(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(X[69999])\n",
        "print(y[69999])\n",
        "\n",
        "def viz(n):\n",
        "    plt.imshow(X[n].reshape(28, 28))\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "#viz(69999)\n",
        "type(y)\n",
        "\n",
        "\n",
        "#------------- Localizar el n\u00famero 4 y graficar la imagen\n",
        "type(y)\n",
        "\n",
        "print(y == 4)       # indica los indices que son iguales a 4 con VERDADERO O FALSO\n",
        "np.where(y == 4)    # regresa los indices que contienen el n\u00famero 4\n",
        "\n",
        "print(y[69977])     # indice del arraglo con valor a 4\n",
        "\n",
        "# a) -- Gr\u00e1fica con c\u00f3digo tradicional\n",
        "_ = X[69977]\n",
        "_image = _.reshape(28, 28)\n",
        "plt.imshow(_image)\n",
        "#plt.show()\n",
        "\n",
        "# b) Con la funci\u00f3n creada anteriormente\n",
        "#viz(69977)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------- Stochastic Gradient Descend (SGD)\n",
        "\n",
        "# M\u00e9todo 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
        "\n",
        "# M\u00e9todo 2\n",
        "num_split = 60000\n",
        "X_train, X_test, y_train, y_test = X[:num_split], X[num_split:], y[:num_split], y[num_split:]\n",
        "\n",
        "#---- Shuffling the DataSet\n",
        "shuffle_index = np.random.permutation(num_split)            # Permutaci\u00f3n es la variaci\u00f3n del orden o posici\u00f3n de elementos.\n",
        "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
        "\n",
        "# TRAINING A BINARY CLASSSIFIER\n",
        "\n",
        "# Necesitamos convertir a cero nuestra variable objetivo\n",
        "y_train_0 = (y_train == 0)      # Hace todo el arreglo a cero de manera autom\u00e1tica. Sin necesidad de utilizar un ciclo\n",
        "y_test_0 = (y_test == 0)\n",
        "\n",
        "\n",
        "\n",
        "# Stochastic Gradient Descend\n",
        "\n",
        "# Entrenamiento\n",
        "clf = SGDClassifier(random_state= 0)        # Random State indica el punto de partida (el origen)\n",
        "clf.fit(X_train, y_train_0)\n",
        "\n",
        "#Prediction\n",
        "viz(1000)\n",
        "clf.predict(X[1000].reshape(1, -1))\n",
        "\n",
        "viz(1001)\n",
        "clf.predict(X[1001].reshape(1, -1))\n",
        "\n",
        "\n",
        "# Performance Measures and Stratified K-FOLD\n",
        "\n",
        "clf = SGDClassifier(random_state=0)         # clf clasificador\n",
        "\n",
        "skfolds = StratifiedKFold(n_splits=3, random_state= 100)\n",
        "\n",
        "for train_index, test_index in skfolds.split(X_train, y_train_0):\n",
        "    clone_clf = clone(clf)\n",
        "    X_train_fold = X_train[train_index]\n",
        "    y_train_folds = (y_train_0[train_index])\n",
        "    X_test_fold = X_train[test_index]\n",
        "    y_test_fold = (y_train_0[test_index])\n",
        "\n",
        "    clone_clf.fit(X_train_fold, y_train_folds)\n",
        "    y_pred = clone_clf.predict(X_test_fold)\n",
        "    n_correct = sum(y_pred == y_test_fold)\n",
        "    print(\"{0:.4f}\".format(n_correct / len(y_pred)))\n",
        "\n",
        "\n",
        "# Forma Alternativa\n",
        "#K-fold cross-validation separa los datos de entrenamiento en K-folds (envolturas-capas) y luego hacer predicciones y evaluarlas\n",
        "crossValScore = cross_val_score(clf, X_train, y_train_0, cv=3, scoring='accuracy')\n",
        "print(crossValScore)\n",
        "\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "y_train_pred = cross_val_predict(clf, X_train, y_train_0, cv= 3)\n",
        "print(y_train_pred)\n",
        "\n",
        "confusionMatrix = confusion_matrix(y_train_0, y_train_pred)\n",
        "print(confusionMatrix)\n",
        "\n",
        "cfMatrix = pd.DataFrame(confusion_matrix(y_train_0, y_train_pred))\n",
        "print(cfMatrix)\n",
        "\n",
        "cfMatrixF = pd.DataFrame(confusionMatrix, columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
        "                         index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']]))\n",
        "\n",
        "print(cfMatrixF)\n",
        "# Precision. Proporci\u00f3n de los casos positivos bien clasificados del modelo respecto al total de predicciones positivas.\n",
        "precisionScore = precision_score(y_train_0, y_train_pred)\n",
        "print(precisionScore)\n",
        "\n",
        "# Sensibilidad. Indice de Verdaderos Positivos (TPR). Proporci\u00f3n de los casos positivos bien clasificados del modelo respecto al total real de positivos.\n",
        "RecallScore = recall_score(y_train_0, y_train_pred)\n",
        "print(RecallScore)\n",
        "\n",
        "F1Score = f1_score(y_train_0, y_train_pred)\n",
        "print(F1Score)\n",
        "\n",
        "\n",
        "# -------------------------------------------------- Precision - Recall Tradeoff\n",
        "np.random.seed(0)\n",
        "clf = SGDClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train_0)\n",
        "\n",
        "y_scores = clf.decision_function(X[1000].reshape(1, -1))\n",
        "print(y_scores)\n",
        "\n",
        "y_scores = clf.decision_function(X[1001].reshape(1, -1))\n",
        "print(y_scores)\n",
        "\n",
        "threshold = 0\n",
        "y_some_digits_pred = (y_scores > threshold)\n",
        "print(y_some_digits_pred)\n",
        "\n",
        "threshold = 40000\n",
        "y_some_digits_pred = (y_scores > threshold)\n",
        "print(y_some_digits_pred)\n",
        "\n",
        "y_scores = cross_val_predict(clf, X_train, y_train_0, cv= 3, method='decision_function')\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.hist(y_scores, bins=100)\n",
        "plt.show()\n",
        "\n",
        "precisions, recalls, threshold = precision_recall_curve(y_train_0, y_scores)\n",
        "\n",
        "def plotRecallPrecisionThreshold(precision, recall, threshold):\n",
        "    plt.plot(threshold, precision[:-1], 'b--', label='Precision')\n",
        "    plt.plot(threshold, recall[:-1], 'g--', label= 'Recall')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.ylim([-0.5, 1.5])\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plotRecallPrecisionThreshold(precisions, recalls, threshold)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#--------------------------------------------- Alterando la Curva Precision-Recall --------------------------------------\n",
        "plt.figure(figsize= (12,8))\n",
        "plt.plot(precisions, recalls)\n",
        "plt.xlabel('recalls')\n",
        "plt.ylabel('precisions')\n",
        "plt.title('PR Curve: precisions/recalls trade off')\n",
        "\n",
        "#Setting precisions at 90%\n",
        "print(len(precisions))\n",
        "print(len(threshold))\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(threshold, precisions[1:])\n",
        "\n",
        "idx = len(precisions[precisions < 0.9])\n",
        "threshold[idx]\n",
        "\n",
        "y_train_pred_90 = (y_scores > 21454)\n",
        "\n",
        "precision90 = precision_score(y_train_0, y_train_pred_90)\n",
        "recall90 = recall_score(y_train_0, y_train_pred_90)\n",
        "\n",
        "print(precision90)\n",
        "print(recall90)\n",
        "\n",
        "# Setting High Recall Recall Score > 0.9\n",
        "\n",
        "idx = len(recalls[recalls > 0.9])\n",
        "threshold[idx]\n",
        "y_train_pred_90 = (y_scores > threshold[idx])\n",
        "\n",
        "precision_score(y_train_0, y_train_pred_90)\n",
        "recall_score(y_train_0, y_train_pred_90)\n",
        "\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(y_train_0, y_scores)\n",
        "\n",
        "def plotROCCurve(fpr, tpr, label=None) :\n",
        "    plt.plot(fpr, tpr, linewidth = 2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.title('ROC CURVE')\n",
        "\n",
        "plt.figure(figsize= (12,8))\n",
        "plotROCCurve(fpr, tpr)\n",
        "plt.show()\n",
        "\n",
        "rocAucScore = roc_auc_score(y_train_0, y_scores)\n",
        "print(rocAucScore)\n",
        "\n",
        "# Random Forest\n",
        "\n",
        "f_clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
        "y_probas_forest = cross_val_predict(f_clf, X_train, y_train_0, cv= 3, method= 'predict_proba')\n",
        "\n",
        "y_scores_forest = y_probas_forest[:, 1]\n",
        "fpr_forest, tpr_forest, threshold_forest = roc_curve(y_train_0, y_scores_forest)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(fpr, tpr, \"b:\", label= \"SGD\")\n",
        "plotROCCurve(fpr_forest, tpr_forest, 'Random Forest')\n",
        "plt.legend(loc= 'lower right')\n",
        "plt.show()\n",
        "\n",
        "roc_auc_score(y_train_0, y_scores_forest)\n",
        "f_clf.fit(X_train, y_train_0)\n",
        "\n",
        "y_train_rf= cross_val_predict(f_clf, X_train, y_train_0, cv=3)\n",
        "precision_score(y_train_0, y_train_rf)\n",
        "\n",
        "precision_score(y_train_0, y_train_rf)\n",
        "recall_score(y_train_0, y_train_rf)\n",
        "\n",
        "confusion_matrix(y_train_0, y_train_rf)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}