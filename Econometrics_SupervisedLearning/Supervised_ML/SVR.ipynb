{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from jedi.api.refactoring import inline\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostRegressor\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "boston_data = load_boston()\n",
        "df = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
        "df.head()\n",
        "\n",
        "y = boston_data.target\n",
        "X = df[['LSTAT']].values\n",
        "\n",
        "# Modelo de Regresi\u00f3n de vectores de soporte SVR(SUPPORT VECTOR REGRESSION)\n",
        "svr = SVR(gamma='auto')\n",
        "svr.fit(X, y)\n",
        "\n",
        "sort_idx =  X.flatten().argsort()\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.scatter(X[sort_idx], y[sort_idx])\n",
        "plt.plot(X[sort_idx], svr.predict(X[sort_idx]), color='k')\n",
        "\n",
        "plt.xlabel('LSTAT')\n",
        "plt.ylabel('MEDV')\n",
        "plt.show()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.3, random_state=42)  #Separa datos en entrenamiento y prueba\n",
        "\n",
        "# Lineal\n",
        "svr = SVR(kernel='linear')\n",
        "svr.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = svr.predict(X_train)\n",
        "y_test_pred = svr.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "R2Score_train = r2_score(y_train, y_train_pred)\n",
        "R2Score_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print('MSE train: {0:.4f}, test: {1:.4f}'.format(mse_train, mse_test))\n",
        "print(\"R2 train: {0: .4f}, test; {1:.4f}\".format(R2Score_train, R2Score_test))\n",
        "\n",
        "\n",
        "#Polynomial\n",
        "svr = SVR(kernel='poly', C=1e3, degree=2, gamma='auto')\n",
        "svr.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = svr.predict(X_train)\n",
        "y_test_pred = svr.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "R2Score_train = r2_score(y_train, y_train_pred)\n",
        "R2Score_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print('MSE train: {0:.4f}, test: {1:.4f}'.format(mse_train, mse_test))\n",
        "print(\"R2 train: {0: .4f}, test; {1:.4f}\".format(R2Score_train, R2Score_test))\n",
        "\n",
        "#rbf kernel\n",
        "svr = SVR(kernel='rbf', C=1e3, gamma='0.1')\n",
        "svr.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = svr.predict(X_train)\n",
        "y_test_pred = svr.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "R2Score_train = r2_score(y_train, y_train_pred)\n",
        "R2Score_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print('MSE train: {0:.4f}, test: {1:.4f}'.format(mse_train, mse_test))\n",
        "print(\"R2 train: {0: .4f}, test; {1:.4f}\".format(R2Score_train, R2Score_test))\n",
        "\n",
        "\n",
        "#------------------------------------------------ C\u00f3digo Resumido -----------------------------------------------------------\n",
        "def SVRTypes(p_X_train, p_y_train, p_X_test, p_y_test, type):\n",
        "\n",
        "    if(type == 'Lineal'):\n",
        "\n",
        "        # Lineal\n",
        "        svr = SVR(kernel='linear')\n",
        "        svr.fit(p_X_train, p_y_train)\n",
        "\n",
        "        y_train_pred = svr.predict(p_X_train)\n",
        "        y_test_pred = svr.predict(p_X_test)\n",
        "\n",
        "        mse_train = mean_squared_error(p_y_train, y_train_pred)\n",
        "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "        R2Score_train = r2_score(p_y_train, y_train_pred)\n",
        "        R2Score_test = r2_score(p_y_test, y_test_pred)\n",
        "\n",
        "        print('MSE train: {0:.4f}, test: {1:.4f}'.format(mse_train, mse_test))\n",
        "        print(\"R2 train: {0: .4f}, test; {1:.4f}\".format(R2Score_train, R2Score_test))\n",
        "\n",
        "    elif(type == 'poly'):\n",
        "        # Polynomial\n",
        "        svr = SVR(kernel='poly', C=1e3, degree=2, gamma='auto')\n",
        "        svr.fit(p_X_train, p_y_train)\n",
        "\n",
        "        y_train_pred = svr.predict(p_X_train)\n",
        "        y_test_pred = svr.predict(p_X_test)\n",
        "\n",
        "        mse_train = mean_squared_error(p_y_train, y_train_pred)\n",
        "        mse_test = mean_squared_error(p_y_test, y_test_pred)\n",
        "\n",
        "        R2Score_train = r2_score(p_y_train, y_train_pred)\n",
        "        R2Score_test = r2_score(p_y_test, y_test_pred)\n",
        "\n",
        "        print('MSE train: {0:.4f}, test: {1:.4f}'.format(mse_train, mse_test))\n",
        "        print(\"R2 train: {0: .4f}, test; {1:.4f}\".format(R2Score_train, R2Score_test))\n",
        "\n",
        "    elif(type == 'rbf'):\n",
        "\n",
        "        # rbf kernel\n",
        "        svr = SVR(kernel='rbf', C=1e3, gamma='0.1')\n",
        "        svr.fit(p_X_train, p_y_train)\n",
        "\n",
        "        y_train_pred = svr.predict(p_X_train)\n",
        "        y_test_pred = svr.predict(p_X_test)\n",
        "\n",
        "        mse_train = mean_squared_error(p_y_train, y_train_pred)\n",
        "        mse_test = mean_squared_error(p_y_test, y_test_pred)\n",
        "\n",
        "        R2Score_train = r2_score(p_y_train, y_train_pred)\n",
        "        R2Score_test = r2_score(p_y_test, y_test_pred)\n",
        "\n",
        "        print('MSE train: {0:.4f}, test: {1:.4f}'.format(mse_train, mse_test))\n",
        "        print(\"R2 train: {0: .4f}, test; {1:.4f}\".format(R2Score_train, R2Score_test))\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "# Ventajas y desventajas del SVM\n",
        "#Ventajas\n",
        "# 1. Efectivo en espacios de dimensiones grandes\n",
        "# 2. Utiliza solo un subconjunto de datos de puntos de entrenamiento (vectores de soporte) en la funci\u00f3n de decisi\u00f3n\n",
        "#3. Muchas funciones de kernels diferentes pueden ser especificados para la funci\u00f3n de decisi\u00f3n\n",
        "# Ejm: lineal, polinomial, radial basis function, sigmoid, custom\n",
        "\n",
        "#Desventajas\n",
        "#Cuidado con la sobreespecificaci\u00f3n del modelo cuando el n\u00famero de caracter\u00edsticas > n\u00famero de muestras\n",
        "# La elecci\u00f3n del kernel y la regularizaci\u00f3n pueden tener un impacto largo en el desempe\u00f1o\n",
        "# No estima probabilidades\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}