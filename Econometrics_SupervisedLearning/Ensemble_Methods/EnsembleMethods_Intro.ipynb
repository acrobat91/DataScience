{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from jedi.api.refactoring import inline\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.datasets import load_iris, make_moons\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score, accuracy_score, classification_report\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet, SGDClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostRegressor, BaggingClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, cross_val_predict, train_test_split\n",
        "from sklearn.base import clone\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import tree\n",
        "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
        "import graphviz\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "#Combinan m\u00faltiples modelos de aprendizaje autom\u00e1tico. Pueden ser regresiones o clasificadores\n",
        "'''\n",
        "\n",
        "Boostrap Aggregating or Bagging:\n",
        "1. Bootstrap es muestreo con reemplazo \n",
        "2. Combina al promediar el resultado (regresion)\n",
        "3. Combina al votar (clasificaci\u00f3n)\n",
        "4. Aplica a muchos clasificadores que incluyen Artificial Neural Network (ANN), CART\n",
        "\n",
        "Pasting\n",
        "Muestreo sin reemplazo\n",
        "\n",
        "Boosting \n",
        "1. Entrena clasificadores d\u00e9biles\n",
        "2. Los a\u00f1ade a un clasificador fuerte final al ponderarlos. (Ponderaci\u00f3n por exactitud t\u00edpicamente)\n",
        "3. Los datos son reponderados\n",
        "\n",
        "4. Muestras que fueron mal clasificadas ganan peso \n",
        "5. Muestras que fueron bien clasificadas pierden peso \n",
        "\n",
        "Stacking\n",
        "1. Tambi\u00e9n conocido como Generalizaci\u00f3n apilada (Stacked), o modelo de segundo nivel\n",
        "2. Combina informaci\u00f3n de m\u00faltiples modelos de predicci\u00f3n para generar un nuevo modelo. Seguido el modelo apilado\n",
        "    supera cada uno de los modelos individuales debido a su suavizamiento y habilidad de sobresaltar cada modelo base donde se\n",
        "    desempe\u00f1a mejor y desacredita aquellos modelos que tienen un pobre rendimiento.\n",
        "3.  Stacking es el m\u00e1s efectivo cuando los modelos base son muy diferentes\n",
        "4. Entrenando un algoritmo de aprendizaje para combinar predicciones de otros algoritmos de aprendizaje \n",
        "'''\n",
        "\n",
        "# BAGGING\n",
        "\n",
        "df = sns.load_dataset('titanic')\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "\n",
        "#df.dropna(inplace=True)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "print(df['pclass'].unique())\n",
        "\n",
        "print(df['pclass'].value_counts())\n",
        "\n",
        "print(df['sex'].value_counts())\n",
        "\n",
        "df['age'].hist(bins=50)\n",
        "plt.show()\n",
        "\n",
        "''' Data Preprocessing '''\n",
        "subset = df[['pclass', 'sex', 'age', 'survived']].copy()\n",
        "subset.dropna(inplace=True)\n",
        "\n",
        "X = subset[['pclass', 'sex', 'age']].copy()\n",
        "\n",
        "le = preprocessing.LabelEncoder()       # Transforma male/ female en unos y ceros\n",
        "\n",
        "X['sex'] = le.fit_transform(subset['sex'])\n",
        "\n",
        "print(X.head())\n",
        "print(X.shape)\n",
        "print(X.describe())\n",
        "print(X.info())\n",
        "\n",
        "y = subset['survived'].copy()\n",
        "print(y.value_counts())\n",
        "\n",
        "\n",
        "# Fit Model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "def print_score(clf, X_train, X_test, y_train, y_test, train=True):\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(y_train)\n",
        "\n",
        "    if train:\n",
        "        '''\n",
        "        training process\n",
        "        '''\n",
        "        res = clf.predict(X_train)\n",
        "        print(\"Train Result: \\n\")\n",
        "        print(\"Accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, res)))\n",
        "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, res)))\n",
        "        print(\"Confussion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, res)))\n",
        "        print(\"ROC AUC: {0:.4f}\\n\".format(roc_auc_score(lb.transform(y_train), lb.transform(res))))\n",
        "\n",
        "    elif train == False:\n",
        "\n",
        "        res_test = clf.predict(X_test)\n",
        "        print(\"Train Result: \\n\")\n",
        "        print(\"Accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, res_test)))\n",
        "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, res_test)))\n",
        "        print(\"Confussion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, res_test)))\n",
        "        print(\"ROC AUC: {0:.4f}\\n\".format(roc_auc_score(lb.transform(y_test), lb.transform(res_test))))\n",
        "\n",
        "\n",
        "''' Decision Tree '''\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print_score(clf, X_train, X_test, y_train, y_test, train=True)\n",
        "print('\\n *************************************************')\n",
        "print_score(clf, X_train, X_test, y_train, y_test, train=False)\n",
        "\n",
        "\n",
        "''' Bagging (oob_score = False) '''\n",
        "\n",
        "'''\n",
        "out of bag : M\u00e9todo de medici\u00f3n para la predicci\u00f3n de los errores de bosques aleatorios, arboles de decisi\u00f3n incrementados y otros \n",
        "modelos de Machine Learning que utilizan agregaci\u00f3n bootstrap (bagging)\n",
        "\n",
        "'''\n",
        "\n",
        "bag_clf = BaggingClassifier(base_estimator=clf, n_estimators=1000, bootstrap=True, n_jobs=-1, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print_score(bag_clf, X_train, X_test, y_train, y_test, train=True)\n",
        "print('\\n *************************************************')\n",
        "print_score(bag_clf, X_train, X_test, y_train, y_test, train=False)\n",
        "\n",
        "\n",
        "'''\n",
        "Bagging(oob_score=True)\n",
        "Utilizamos las muestras out of bag (predicci\u00f3n de errores) para estimar la exactitud generalizada\n",
        "'''\n",
        "\n",
        "\n",
        "bag_clf = BaggingClassifier(base_estimator=clf, n_estimators=1000, bootstrap=True, oob_score=True, n_jobs=-1, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print_score(bag_clf, X_train, X_test, y_train, y_test, train=True)\n",
        "print('\\n *************************************************')\n",
        "print_score(bag_clf, X_train, X_test, y_train, y_test, train=False)\n",
        "\n",
        "\n",
        "print(bag_clf.oob_score_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Gradient Boosting Machine\n",
        "\n",
        "'''\n",
        "\n",
        "gbc_clf = GradientBoostingClassifier()\n",
        "gbc_clf.fit(X_train, y_train)\n",
        "\n",
        "print_score(gbc_clf, X_train, X_test, y_train, y_test, train=True)\n",
        "print('\\n *************************************************')\n",
        "print_score(gbc_clf, X_train, X_test, y_train, y_test, train=False)\n",
        "\n",
        "\n",
        "'''\n",
        "XGBOOST\n",
        "'''\n",
        "\n",
        "data = np.random.rand(100,10) # 5 entidades cada una contiene 10 caracter\u00edsticas\n",
        "label = np.random.randint(2, size=100)\n",
        "dtrain = xgb.DMatrix(data, label=label)\n",
        "\n",
        "dtest = dtrain\n",
        "\n",
        "param = {'bst:max_depth': 2, 'bst:eta' : 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
        "param['nthread'] = 4\n",
        "param['eval_metric'] = 'auc'\n",
        "\n",
        "evallist = [(dtest, 'eval'),(dtrain, 'train')]\n",
        "\n",
        "num_round = 10\n",
        "bst = xgb.train(param, dtrain, num_round, evallist)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}